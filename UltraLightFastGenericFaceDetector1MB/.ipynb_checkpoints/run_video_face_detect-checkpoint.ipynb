{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'vision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-117f037183b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefine_img_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m parser = argparse.ArgumentParser(\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vision'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This code uses the pytorch model to detect faces from live video or camera.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "from vision.ssd.config.fd_config import define_img_size\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='detect_video')\n",
    "\n",
    "parser.add_argument('--net_type', default=\"RFB\", type=str,\n",
    "                    help='The network architecture ,optional: RFB (higher precision) or slim (faster)')\n",
    "parser.add_argument('--input_size', default=480, type=int,\n",
    "                    help='define network input size,default optional value 128/160/320/480/640/1280')\n",
    "parser.add_argument('--threshold', default=0.7, type=float,\n",
    "                    help='score threshold')\n",
    "parser.add_argument('--candidate_size', default=1000, type=int,\n",
    "                    help='nms candidate size')\n",
    "parser.add_argument('--path', default=\"imgs\", type=str,\n",
    "                    help='imgs dir')\n",
    "parser.add_argument('--test_device', default=\"cuda:0\", type=str,\n",
    "                    help='cuda:0 or cpu')\n",
    "parser.add_argument('--video_path', default=\"/home/linzai/Videos/video/16_1.MP4\", type=str,\n",
    "                    help='path of video')\n",
    "\n",
    "#args = parser.parse_args()\n",
    "args = parser.parse_args(\"\")## Modified by Rong Li for runing on Jupyter Notebook\n",
    "args.video_path = \"videos\" ## Modified by Rong Li\n",
    "\n",
    "input_img_size = args.input_size\n",
    "define_img_size(input_img_size)  # must put define_img_size() before 'import create_mb_tiny_fd, create_mb_tiny_fd_predictor'\n",
    "\n",
    "from vision.ssd.mb_tiny_fd import create_mb_tiny_fd, create_mb_tiny_fd_predictor\n",
    "from vision.ssd.mb_tiny_RFB_fd import create_Mb_Tiny_RFB_fd, create_Mb_Tiny_RFB_fd_predictor\n",
    "from vision.utils.misc import Timer\n",
    "\n",
    "label_path = \"./models/voc-model-labels.txt\"\n",
    "\n",
    "net_type = args.net_type\n",
    "\n",
    "cap = cv2.VideoCapture(args.video_path)  # capture from video\n",
    "# cap = cv2.VideoCapture(0)  # capture from camera\n",
    "\n",
    "class_names = [name.strip() for name in open(label_path).readlines()]\n",
    "num_classes = len(class_names)\n",
    "test_device = \"cpu\" # Rong Li: args.test_device\n",
    "\n",
    "candidate_size = args.candidate_size\n",
    "threshold = args.threshold\n",
    "\n",
    "if net_type == 'slim':\n",
    "    model_path = \"models/pretrained/version-slim-320.pth\"\n",
    "    # model_path = \"models/pretrained/version-slim-640.pth\"\n",
    "    net = create_mb_tiny_fd(len(class_names), is_test=True, device=test_device)\n",
    "    predictor = create_mb_tiny_fd_predictor(net, candidate_size=candidate_size, device=test_device)\n",
    "elif net_type == 'RFB':\n",
    "    model_path = \"models/pretrained/version-RFB-320.pth\"\n",
    "    # model_path = \"models/pretrained/version-RFB-640.pth\"\n",
    "    net = create_Mb_Tiny_RFB_fd(len(class_names), is_test=True, device=test_device)\n",
    "    predictor = create_Mb_Tiny_RFB_fd_predictor(net, candidate_size=candidate_size, device=test_device)\n",
    "else:\n",
    "    print(\"The net type is wrong!\")\n",
    "    sys.exit(1)\n",
    "net.load(model_path)\n",
    "\n",
    "timer = Timer()\n",
    "sum = 0\n",
    "while True:\n",
    "    ret, orig_image = cap.read()\n",
    "    if orig_image is None:\n",
    "        print(\"end\")\n",
    "        break\n",
    "    image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "    timer.start()\n",
    "    boxes, labels, probs = predictor.predict(image, candidate_size / 2, threshold)\n",
    "    interval = timer.end()\n",
    "    print('Time: {:.6f}s, Detect Objects: {:d}.'.format(interval, labels.size(0)))\n",
    "    for i in range(boxes.size(0)):\n",
    "        box = boxes[i, :]\n",
    "        label = f\" {probs[i]:.2f}\"\n",
    "        cv2.rectangle(orig_image, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 4)\n",
    "\n",
    "        # cv2.putText(orig_image, label,\n",
    "        #             (box[0], box[1] - 10),\n",
    "        #             cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        #             0.5,  # font scale\n",
    "        #             (0, 0, 255),\n",
    "        #             2)  # line type\n",
    "    orig_image = cv2.resize(orig_image, None, None, fx=0.8, fy=0.8)\n",
    "    sum += boxes.size(0)\n",
    "    cv2.imshow('annotated', orig_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"all face num:{}\".format(sum))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
